# KI-Training fÃ¼r AnfÃ¤nger: Blumen-Klassifikation
# ================================================
# Dieses Notebook zeigt, wie eine einfache KI trainiert wird
# JupyterLite-kompatibel

# %% [markdown]
"""
## 1. EinfÃ¼hrung
In diesem Notebook lernen wir:
- Wie man Daten fÃ¼r KI vorbereitet
- Wie man ein einfaches neuronales Netz erstellt
- Wie man die KI trainiert
- Wie man die Genauigkeit testet

Wir verwenden den bekannten **Iris-Datensatz** mit 3 Blumenarten.
"""

# %% [markdown]
"""
## 2. Bibliotheken installieren (nur fÃ¼r JupyterLite nÃ¶tig)
"""

# %%
# In JupyterLite mÃ¼ssen wir Pakete mit piplite installieren
import sys
if 'pyodide' in sys.modules:
    import piplite
    await piplite.install(['numpy', 'pandas', 'matplotlib', 'scikit-learn'])
    print("âœ“ Pakete fÃ¼r JupyterLite installiert!")

# %% [markdown]
"""
## 3. Bibliotheken importieren
"""

# %%
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

print("âœ“ Alle Bibliotheken erfolgreich importiert!")

# %% [markdown]
"""
## 4. Daten laden und erkunden
"""

# %%
# Iris-Datensatz laden
iris = load_iris()
X = iris.data  # Features: Kelchblatt- und BlÃ¼tenblatt-MaÃŸe
y = iris.target  # Zielwerte: Blumenart (0, 1, oder 2)

# Als DataFrame anzeigen fÃ¼r bessere Lesbarkeit
df = pd.DataFrame(X, columns=iris.feature_names)
df['Blumenart'] = pd.Categorical.from_codes(y, iris.target_names)

print("ğŸ“Š Erste 5 Zeilen unserer Daten:")
print(df.head())
print(f"\nğŸ“ˆ Datensatz enthÃ¤lt {len(df)} Blumen")
print(f"ğŸŒ¸ Blumenarten: {', '.join(iris.target_names)}")

# %% [markdown]
"""
## 4. Daten visualisieren
"""

# %%
# Streudiagramm: KelchblattlÃ¤nge vs. Kelchblattbreite
plt.figure(figsize=(10, 6))
colors = ['red', 'green', 'blue']
for i, species in enumerate(iris.target_names):
    plt.scatter(X[y == i, 0], X[y == i, 1], 
                c=colors[i], label=species, alpha=0.6, s=100)

plt.xlabel('KelchblattlÃ¤nge (cm)', fontsize=12)
plt.ylabel('Kelchblattbreite (cm)', fontsize=12)
plt.title('Iris-Blumen: Unterschiede in den MaÃŸen', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

print("ğŸ’¡ Die verschiedenen Blumenarten haben unterschiedliche MaÃŸe!")
print("   Das ist genau das Muster, das unsere KI lernen soll.")

# %% [markdown]
"""
## 5. Daten aufteilen: Training vs. Test
"""

# %%
# 80% Training, 20% Test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"ğŸ”§ Trainingsdaten: {len(X_train)} Blumen")
print(f"ğŸ§ª Testdaten: {len(X_test)} Blumen")
print("\nğŸ’­ Warum aufteilen?")
print("   â†’ Training: Damit lernt die KI")
print("   â†’ Test: Damit prÃ¼fen wir, ob sie wirklich gelernt hat")

# %% [markdown]
"""
## 6. Daten normalisieren
"""

# %%
# Daten auf Ã¤hnliche Skala bringen
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("ğŸ“ Daten wurden normalisiert")
print("\nğŸ’­ Warum normalisieren?")
print("   â†’ Alle Merkmale haben unterschiedliche Einheiten")
print("   â†’ Normalisierung hilft der KI, besser zu lernen")
print(f"\n   Vorher (Beispiel): {X_train[0]}")
print(f"   Nachher: {X_train_scaled[0]}")

# %% [markdown]
"""
## 7. KI-Modell erstellen
"""

# %%
# Neuronales Netz mit 2 versteckten Schichten
model = MLPClassifier(
    hidden_layer_sizes=(10, 10),  # 2 Schichten mit je 10 Neuronen
    max_iter=1000,                # Maximal 1000 Trainingsrunden
    random_state=42,
    verbose=True                  # Fortschritt anzeigen
)

print("ğŸ§  Neuronales Netz erstellt!")
print("\nğŸ“ Architektur:")
print("   Eingabe: 4 Neuronen (fÃ¼r 4 Merkmale)")
print("   Versteckte Schicht 1: 10 Neuronen")
print("   Versteckte Schicht 2: 10 Neuronen")
print("   Ausgabe: 3 Neuronen (fÃ¼r 3 Blumenarten)")

# %% [markdown]
"""
## 8. Training starten! ğŸš€
"""

# %%
print("â³ Training lÃ¤uft...\n")
model.fit(X_train_scaled, y_train)
print("\nâœ… Training abgeschlossen!")

# %% [markdown]
"""
## 9. KI testen
"""

# %%
# Vorhersagen auf Testdaten
y_pred = model.predict(X_test_scaled)

# Genauigkeit berechnen
accuracy = accuracy_score(y_test, y_pred)
print(f"ğŸ¯ Genauigkeit auf Testdaten: {accuracy * 100:.1f}%")

# Einzelne Vorhersagen anzeigen
print("\nğŸ” Beispiel-Vorhersagen (erste 10 Testblumen):")
print("-" * 50)
for i in range(min(10, len(y_test))):
    actual = iris.target_names[y_test[i]]
    predicted = iris.target_names[y_pred[i]]
    status = "âœ“" if y_test[i] == y_pred[i] else "âœ—"
    print(f"{status} TatsÃ¤chlich: {actual:15} | Vorhergesagt: {predicted}")

# %% [markdown]
"""
## 10. Confusion Matrix: Wo macht die KI Fehler?
"""

# %%
# Confusion Matrix erstellen
cm = confusion_matrix(y_test, y_pred)

# Visualisieren
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=iris.target_names,
            yticklabels=iris.target_names)
plt.ylabel('TatsÃ¤chliche Klasse')
plt.xlabel('Vorhergesagte Klasse')
plt.title('Confusion Matrix: Wie gut ist unsere KI?')
plt.show()

print("\nğŸ’¡ So liest du die Matrix:")
print("   â†’ Diagonale (oben links nach unten rechts) = richtige Vorhersagen")
print("   â†’ Andere Felder = Fehler der KI")

# %% [markdown]
"""
## 11. Eigene Vorhersage machen
"""

# %%
# Beispiel: Eine neue Blume klassifizieren
neue_blume = np.array([[5.1, 3.5, 1.4, 0.2]])  # Kelch- und BlÃ¼tenblatt-MaÃŸe

# Normalisieren und vorhersagen
neue_blume_scaled = scaler.transform(neue_blume)
vorhersage = model.predict(neue_blume_scaled)
wahrscheinlichkeiten = model.predict_proba(neue_blume_scaled)

print("ğŸŒº Neue Blume klassifizieren:")
print(f"   MaÃŸe: Kelchblatt {neue_blume[0][0]}Ã—{neue_blume[0][1]} cm, "
      f"BlÃ¼tenblatt {neue_blume[0][2]}Ã—{neue_blume[0][3]} cm")
print(f"\nğŸ¤– KI sagt: {iris.target_names[vorhersage[0]]}")
print("\nğŸ“Š Wahrscheinlichkeiten:")
for i, species in enumerate(iris.target_names):
    print(f"   {species}: {wahrscheinlichkeiten[0][i] * 100:.1f}%")

# %% [markdown]
"""
## 12. Zusammenfassung

### Was haben wir gelernt? ğŸ“

1. **Daten laden**: Wir haben einen Datensatz mit BlumenmaÃŸen geladen
2. **Daten erkunden**: Visualisierung zeigt Unterschiede zwischen Arten
3. **Daten aufteilen**: Training (80%) und Test (20%)
4. **Normalisierung**: Daten auf gleiche Skala bringen
5. **Modell erstellen**: Neuronales Netz mit 2 Schichten
6. **Training**: KI lernt Muster aus Trainingsdaten
7. **Testen**: ÃœberprÃ¼fung auf ungesehenen Daten
8. **Vorhersagen**: KI kann neue Blumen klassifizieren

### NÃ¤chste Schritte ğŸš€

- Experimentiere mit anderen Netzwerk-Architekturen (mehr/weniger Neuronen)
- VerÃ¤ndere die Anzahl der Trainingsrunden (max_iter)
- Probiere andere DatensÃ¤tze aus
- Lerne Ã¼ber verschiedene Arten von KI-Modellen

### Wichtige Konzepte ğŸ’¡

- **Training**: KI lernt aus Beispielen
- **Testen**: ÃœberprÃ¼fung auf neuen Daten (nicht beim Training gesehen)
- **Overfitting**: Wenn KI Trainingsdaten auswendig lernt statt Muster
- **Genauigkeit**: Wie oft liegt die KI richtig?
"""

# %%
print("ğŸ‰ Herzlichen GlÃ¼ckwunsch!")
print("   Du hast deine erste KI trainiert!")
print("\nğŸ’ª Experimentiere weiter und viel Erfolg!")
