{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 3: Neuronales Netz\n",
    "\n",
    "## Überwachtes Lernen\n",
    "\n",
    "Im letzten Teil hat K-Means Gruppen gefunden, **ohne die Antworten zu kennen**. Das war beeindruckend - aber wir HABEN ja die richtigen Antworten! Wir wissen, welche Blume zu welcher Art gehört.\n",
    "\n",
    "**Warum dieses Wissen nicht nutzen?**\n",
    "\n",
    "Ein **neuronales Netz** lernt aus Beispielen MIT den richtigen Antworten:\n",
    "1. Wir zeigen der KI eine Blume und sagen: \"Das ist eine Setosa\"\n",
    "2. Die KI merkt sich, welche Messungen zu Setosa gehören\n",
    "3. Nach vielen Beispielen kann sie neue Blumen selbst erkennen\n",
    "\n",
    "Das nennt man **überwachtes Lernen** - wie ein Schüler, der von einem Lehrer lernt.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module und Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*as_object_map.*\")\n",
    "\n",
    "if \"pyodide\" in sys.modules:\n",
    "    import piplite\n",
    "    await piplite.install([\"numpy\", \"pandas\", \"matplotlib\", \"scikit-learn\"])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "df = pd.read_csv(\"data/iris.csv\")\n",
    "print(f\"Daten geladen: {len(df)} Blumen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 1: Daten aufteilen\n",
    "\n",
    "### Das Prüfungs-Prinzip\n",
    "\n",
    "Stell dir vor, du lernst für eine Mathe-Prüfung:\n",
    "- Du übst mit **Übungsaufgaben** (= Trainingsdaten)\n",
    "- Die Prüfung hat **neue Aufgaben** (= Testdaten)\n",
    "\n",
    "Wenn die Prüfung die gleichen Aufgaben hätte wie beim Üben, wüssten wir nicht, ob du Mathe wirklich verstanden hast - oder nur auswendig gelernt hast!\n",
    "\n",
    "**Genau so bei der KI:**\n",
    "- **80% der Blumen** = Trainingsdaten (zum Lernen)\n",
    "- **20% der Blumen** = Testdaten (für die \"Prüfung\")\n",
    "\n",
    "Die KI sieht die Testblumen erst ganz am Schluss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]]\n",
    "y = df[\"species\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Trainingsdaten: {len(X_train)} Blumen | Testdaten: {len(X_test)} Blumen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Warum Daten aufteilen?\n",
    "\n",
    "1. Erkläre in deinen eigenen Worten, warum es unfair wäre, wenn eine Prüfung genau die gleichen Aufgaben hätte wie die Übungen.\n",
    "\n",
    "2. Was würde passieren, wenn wir die KI mit ALLEN 150 Blumen trainieren und dann mit den gleichen testen?\n",
    "\n",
    "3. **Overfitting**: Wenn eine KI die Trainingsdaten \"auswendig lernt\" statt Muster zu erkennen. Erkläre das mit einem Schul-Beispiel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deine Antworten zu Aufgabe 1\n",
    "\n",
    "**1. Warum wäre es unfair?**\n",
    "\n",
    "*Doppelklicke hier und schreibe deine Antwort...*\n",
    "\n",
    "**2. Was würde passieren?**\n",
    "\n",
    "*Doppelklicke hier und schreibe deine Antwort...*\n",
    "\n",
    "**3. Overfitting-Beispiel:**\n",
    "\n",
    "*Doppelklicke hier und schreibe deine Antwort...*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 2: Normalisierung\n",
    "\n",
    "### Warum brauchen wir das?\n",
    "\n",
    "Stell dir vor, du vergleichst:\n",
    "- Körpergrösse: 170 cm\n",
    "- Schuhgrösse: 42\n",
    "\n",
    "Die KI könnte denken: \"170 ist viel grösser als 42, also ist Körpergrösse wichtiger!\" Das stimmt aber nicht.\n",
    "\n",
    "**Normalisierung** bringt alle Werte auf eine ähnliche Skala (ungefähr zwischen -2 und +2). So sind alle Messungen gleich wichtig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Vorher:  {X_train.iloc[0].values}\")\n",
    "print(f\"Nachher: {X_train_scaled[0].round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 3: Neuronales Netz erstellen\n",
    "\n",
    "### Was ist ein neuronales Netz?\n",
    "\n",
    "Das Gehirn besteht aus Milliarden von **Neuronen** (Nervenzellen), die miteinander verbunden sind. Ein neuronales Netz in der Informatik funktioniert ähnlich - aber viel einfacher.\n",
    "\n",
    "### Die Team-Analogie\n",
    "\n",
    "Stell dir ein Team von Experten vor:\n",
    "1. **Eingangsteam (4 Personen):** Nimmt die 4 Messungen entgegen\n",
    "2. **Denkteam 1 (10 Personen):** Kombiniert die Informationen\n",
    "3. **Denkteam 2 (10 Personen):** Verfeinert die Entscheidung\n",
    "4. **Ausgangsteam (3 Personen):** Gibt die Wahrscheinlichkeit für jede Blumenart aus\n",
    "\n",
    "```\n",
    "[4 Eingänge] → [10 Neuronen] → [10 Neuronen] → [3 Ausgänge]\n",
    "   Messungen       \"Denken\"       \"Denken\"      Blumenarten\n",
    "```\n",
    "\n",
    "Jede Person (Neuron) ist mit allen Personen der nächsten Stufe verbunden. Beim Training lernt das Netz, wie stark jede Verbindung sein soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42)\n",
    "print(\"Netz erstellt: [4] → [10] → [10] → [3]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 4: Training\n",
    "\n",
    "### Wie lernt die KI?\n",
    "\n",
    "Das Training läuft in vielen Runden (hier bis zu 1000):\n",
    "\n",
    "1. **Raten:** Die KI schaut sich eine Blume an und rät die Art\n",
    "2. **Feedback:** Wir sagen ihr, ob sie richtig oder falsch lag\n",
    "3. **Anpassen:** Sie verstärkt die Verbindungen, die zur richtigen Antwort führten\n",
    "4. **Wiederholen:** Das macht sie mit allen 120 Trainingsblumen, immer wieder\n",
    "\n",
    "Mit jeder Runde wird die KI ein bisschen besser - wie ein Schüler, der immer wieder übt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Training abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 5: Die grosse Prüfung!\n",
    "\n",
    "Jetzt zeigen wir der KI die 30 Testblumen, die sie noch NIE gesehen hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Ergebnis: {(y_test == y_pred).sum()}/{len(y_test)} richtig = {accuracy*100:.1f}% Genauigkeit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einzelne Vorhersagen anschauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Die ersten 10 Vorhersagen:\\n\")\n",
    "for i in range(min(10, len(y_test))):\n",
    "    actual, predicted = y_test.iloc[i], y_pred[i]\n",
    "    status = \"Richtig\" if actual == predicted else f\"Fehler ({predicted})\"\n",
    "    print(f\"Blume {i+1}: {actual} → {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "Die **Confusion Matrix** (Verwirrungsmatrix) zeigt uns genau, wo die KI Fehler macht.\n",
    "\n",
    "### Wie liest man sie?\n",
    "\n",
    "- **Zeilen** = Die echten Blumenarten\n",
    "- **Spalten** = Was die KI geraten hat\n",
    "- **Diagonale** (von oben-links nach unten-rechts) = Richtig erkannt!\n",
    "- **Daneben** = Fehler (Verwechslungen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "species_names = df[\"species\"].unique()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "\n",
    "ax.set(xticks=range(3), yticks=range(3), xticklabels=species_names, yticklabels=species_names,\n",
    "       xlabel=\"Vorhergesagt\", ylabel=\"Tatsächlich\", title=\"Confusion Matrix\")\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", \n",
    "                color=\"white\" if cm[i, j] > cm.max()/2 else \"black\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "plt.colorbar(im)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Diagonale = richtig erkannt, daneben = Fehler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2: Die Confusion Matrix lesen\n",
    "\n",
    "1. **Zähle zusammen:** Wie viele Blumen wurden insgesamt RICHTIG erkannt?\n",
    "\n",
    "2. **Fehler finden:** Welche Blumenarten wurden verwechselt?\n",
    "\n",
    "3. **Genauigkeit berechnen:** Accuracy = Richtige / Gesamt x 100%. Stimmt dein Ergebnis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deine Antworten zu Aufgabe 2\n",
    "\n",
    "**1. Anzahl richtig erkannter Blumen:**\n",
    "\n",
    "*Doppelklicke hier und schreibe deine Antwort...*\n",
    "\n",
    "**2. Welche Arten wurden verwechselt?**\n",
    "\n",
    "*Doppelklicke hier und schreibe deine Antwort...*\n",
    "\n",
    "**3. Deine Genauigkeits-Berechnung:**\n",
    "\n",
    "*Doppelklicke hier und schreibe deine Antwort...*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste die KI mit einer neuen Blume!\n",
    "\n",
    "Ändere die Werte und führe die Zelle nochmal aus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format: [Kelchblatt-Länge, Kelchblatt-Breite, Blütenblatt-Länge, Blütenblatt-Breite]\n",
    "neue_blume = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
    "\n",
    "neue_blume_scaled = scaler.transform(neue_blume)\n",
    "vorhersage = model.predict(neue_blume_scaled)\n",
    "proba = model.predict_proba(neue_blume_scaled)[0]\n",
    "\n",
    "print(f\"Messungen: Kelchblatt {neue_blume[0][0]}x{neue_blume[0][1]} cm, Blütenblatt {neue_blume[0][2]}x{neue_blume[0][3]} cm\")\n",
    "print(f\"\\nVorhersage: {vorhersage[0]}\")\n",
    "print(f\"\\nWahrscheinlichkeiten:\")\n",
    "for species, p in zip(df[\"species\"].unique(), proba):\n",
    "    print(f\"   {species}: {'█' * int(p*20)} {p*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentiere selbst!\n",
    "\n",
    "```python\n",
    "# Typische Setosa (kleine Blütenblätter):\n",
    "neue_blume = np.array([[5.0, 3.5, 1.3, 0.3]])\n",
    "\n",
    "# Typische Versicolor (mittlere Grösse):\n",
    "neue_blume = np.array([[6.0, 2.7, 4.5, 1.5]])\n",
    "\n",
    "# Typische Virginica (grosse Blütenblätter):\n",
    "neue_blume = np.array([[6.5, 3.0, 5.5, 2.0]])\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "### Was wir in allen drei Notebooks gelernt haben\n",
    "\n",
    "| Begriff | Bedeutung |\n",
    "|---------|----------|\n",
    "| **Maschinelles Lernen** | Computer lernen aus Daten statt durch Programmierung |\n",
    "| **Features** | Die Merkmale/Eingaben (unsere 4 Messungen) |\n",
    "| **Labels** | Die richtigen Antworten (Blumenarten) |\n",
    "| **Unüberwachtes Lernen** | KI sucht Muster ohne Antworten (K-Means) |\n",
    "| **Überwachtes Lernen** | KI lernt aus Beispielen MIT Antworten (Neuronales Netz) |\n",
    "| **Trainingsdaten** | Daten zum Lernen (80%) |\n",
    "| **Testdaten** | Daten für die \"Prüfung\" (20%) |\n",
    "| **Normalisierung** | Alle Werte auf gleiche Skala bringen |\n",
    "| **Overfitting** | Auswendig lernen statt Muster verstehen |\n",
    "| **Accuracy** | Wie oft liegt die KI richtig? (Anzahl richtige / Gesamt) |\n",
    "\n",
    "### Der Unterschied\n",
    "\n",
    "| | K-Means | Neuronales Netz |\n",
    "|-|---------|----------------|\n",
    "| **Lernt aus** | Nur den Daten | Daten + richtige Antworten |\n",
    "| **Braucht** | Anzahl Gruppen (K) | Trainingsbeispiele mit Labels |\n",
    "| **Kann** | Gruppen finden | Neue Daten klassifizieren |\n",
    "| **Typisch für** | Unbekannte Daten sortieren | Bekannte Kategorien erkennen |\n",
    "\n",
    "---\n",
    "\n",
    "### Glückwunsch!\n",
    "\n",
    "Du hast gerade:\n",
    "- Einen echten Datensatz aus dem Jahr 1936 analysiert\n",
    "- K-Means Clustering ausprobiert (unüberwachtes Lernen)\n",
    "- Ein neuronales Netz trainiert (überwachtes Lernen)\n",
    "- Die Qualität mit Testdaten überprüft\n",
    "\n",
    "**Das ist genau der Prozess, den auch professionelle Data Scientists verwenden!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
